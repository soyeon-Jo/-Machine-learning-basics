{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b02640",
   "metadata": {},
   "source": [
    "# Linear_Regression \n",
    "#### 데이터 청년 캠퍼스_서울여자대학교 과정\n",
    "python의 scikit-learn 패키지를 이용해 다중 회귀분석을 직접 실행해보려 한다.\n",
    "\n",
    "- Scikit-learn에서는 데이터 분석 연습을 위한 몇 가지의 toy dataset을 제공하고 있다. 그 중 이번 시간에 사용할 데이터셋은 diabetes dataset이다.\n",
    "\n",
    "- Diabetes dataset은 당뇨병 환자들의 1년간 당뇨병 진행 변화에 대한 데이터이다. 독립 변수는 나이와 성별 등 환자의 정보이며, 예측해야 하는 종속 변수는 당뇨병의 진행 정도이다. \n",
    "\n",
    "*결측치가 없고 데이터 정규화도 되어 있어 제공된 그대로 분석에 사용 한다.*\n",
    "\n",
    "**sklearn의 회귀분석 순서**\n",
    "1. 원하는 클래스 import\n",
    "2. 객체 생성\n",
    "3. fit() 적용 : 모형 생성, 즉 데이터를 가장 잘 설명하는 선형식 - 쉽게 말해서 <u>직선을 찾는다</u>. **fit()이 수행되면 기울기와 절편이 결정**된다.\n",
    "4. 모형 기본정보 확인 : fit()에서 결정된 기울기, 절편 등을 확인한다.\n",
    "5. score()로 성능 검사 : R2(R square)라고 해서 모형의 설명력을 나타내는 수치를 계산한다.\n",
    "6. predict()로 예측 : 새로운 독립변수를 이용하여 종속변수를 예측한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f467a8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : [[ 0.03807591  0.05068012  0.06169621 ... -0.00259226  0.01990842\n",
      "  -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 ... -0.03949338 -0.06832974\n",
      "  -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 ... -0.00259226  0.00286377\n",
      "  -0.02593034]\n",
      " ...\n",
      " [ 0.04170844  0.05068012 -0.01590626 ... -0.01107952 -0.04687948\n",
      "   0.01549073]\n",
      " [-0.04547248 -0.04464164  0.03906215 ...  0.02655962  0.04452837\n",
      "  -0.02593034]\n",
      " [-0.04547248 -0.04464164 -0.0730303  ... -0.03949338 -0.00421986\n",
      "   0.00306441]]\n",
      "target : [151.  75. 141. 206. 135.  97. 138.  63. 110. 310. 101.  69. 179. 185.\n",
      " 118. 171. 166. 144.  97. 168.  68.  49.  68. 245. 184. 202. 137.  85.\n",
      " 131. 283. 129.  59. 341.  87.  65. 102. 265. 276. 252.  90. 100.  55.\n",
      "  61.  92. 259.  53. 190. 142.  75. 142. 155. 225.  59. 104. 182. 128.\n",
      "  52.  37. 170. 170.  61. 144.  52. 128.  71. 163. 150.  97. 160. 178.\n",
      "  48. 270. 202. 111.  85.  42. 170. 200. 252. 113. 143.  51.  52. 210.\n",
      "  65. 141.  55. 134.  42. 111.  98. 164.  48.  96.  90. 162. 150. 279.\n",
      "  92.  83. 128. 102. 302. 198.  95.  53. 134. 144. 232.  81. 104.  59.\n",
      " 246. 297. 258. 229. 275. 281. 179. 200. 200. 173. 180.  84. 121. 161.\n",
      "  99. 109. 115. 268. 274. 158. 107.  83. 103. 272.  85. 280. 336. 281.\n",
      " 118. 317. 235.  60. 174. 259. 178. 128.  96. 126. 288.  88. 292.  71.\n",
      " 197. 186.  25.  84.  96. 195.  53. 217. 172. 131. 214.  59.  70. 220.\n",
      " 268. 152.  47.  74. 295. 101. 151. 127. 237. 225.  81. 151. 107.  64.\n",
      " 138. 185. 265. 101. 137. 143. 141.  79. 292. 178.  91. 116.  86. 122.\n",
      "  72. 129. 142.  90. 158.  39. 196. 222. 277.  99. 196. 202. 155.  77.\n",
      " 191.  70.  73.  49.  65. 263. 248. 296. 214. 185.  78.  93. 252. 150.\n",
      "  77. 208.  77. 108. 160.  53. 220. 154. 259.  90. 246. 124.  67.  72.\n",
      " 257. 262. 275. 177.  71.  47. 187. 125.  78.  51. 258. 215. 303. 243.\n",
      "  91. 150. 310. 153. 346.  63.  89.  50.  39. 103. 308. 116. 145.  74.\n",
      "  45. 115. 264.  87. 202. 127. 182. 241.  66.  94. 283.  64. 102. 200.\n",
      " 265.  94. 230. 181. 156. 233.  60. 219.  80.  68. 332. 248.  84. 200.\n",
      "  55.  85.  89.  31. 129.  83. 275.  65. 198. 236. 253. 124.  44. 172.\n",
      " 114. 142. 109. 180. 144. 163. 147.  97. 220. 190. 109. 191. 122. 230.\n",
      " 242. 248. 249. 192. 131. 237.  78. 135. 244. 199. 270. 164.  72.  96.\n",
      " 306.  91. 214.  95. 216. 263. 178. 113. 200. 139. 139.  88. 148.  88.\n",
      " 243.  71.  77. 109. 272.  60.  54. 221.  90. 311. 281. 182. 321.  58.\n",
      " 262. 206. 233. 242. 123. 167.  63. 197.  71. 168. 140. 217. 121. 235.\n",
      " 245.  40.  52. 104. 132.  88.  69. 219.  72. 201. 110.  51. 277.  63.\n",
      " 118.  69. 273. 258.  43. 198. 242. 232. 175.  93. 168. 275. 293. 281.\n",
      "  72. 140. 189. 181. 209. 136. 261. 113. 131. 174. 257.  55.  84.  42.\n",
      " 146. 212. 233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.\n",
      "  49.  64.  48. 178. 104. 132. 220.  57.]\n",
      "frame : None\n",
      "DESCR : .. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "feature_names : ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "data_filename : C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\data\\diabetes_data.csv.gz\n",
      "target_filename : C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\data\\diabetes_target.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# 패키지 삽입\n",
    "from sklearn import datasets\n",
    "\n",
    "# data 불러오기\n",
    "data = datasets.load_diabetes()\n",
    "\n",
    "# data 살펴보기\n",
    "for k,v in data.items():\n",
    "    print(k,':',v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf950a",
   "metadata": {},
   "source": [
    "- x: 독립 변수\n",
    "- y: 종속 변수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb6d8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10) (442,)\n",
      "x: [[ 0.03807591  0.05068012  0.06169621  0.02187235 -0.0442235  -0.03482076\n",
      "  -0.04340085 -0.00259226  0.01990842 -0.01764613]\n",
      " [-0.00188202 -0.04464164 -0.05147406 -0.02632783 -0.00844872 -0.01916334\n",
      "   0.07441156 -0.03949338 -0.06832974 -0.09220405]\n",
      " [ 0.08529891  0.05068012  0.04445121 -0.00567061 -0.04559945 -0.03419447\n",
      "  -0.03235593 -0.00259226  0.00286377 -0.02593034]\n",
      " [-0.08906294 -0.04464164 -0.01159501 -0.03665645  0.01219057  0.02499059\n",
      "  -0.03603757  0.03430886  0.02269202 -0.00936191]\n",
      " [ 0.00538306 -0.04464164 -0.03638469  0.02187235  0.00393485  0.01559614\n",
      "   0.00814208 -0.00259226 -0.03199144 -0.04664087]] \n",
      " y: [151.  75. 141. 206. 135.]\n"
     ]
    }
   ],
   "source": [
    "# 독립변수, 종속변수 나누기 및 확인\n",
    "x = data['data']\n",
    "y = data['target']\n",
    "\n",
    "print(x.shape,y.shape)\n",
    "print('x:',x[:5],'\\n y:', y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08a48a",
   "metadata": {},
   "source": [
    "### 데이터 분할하기\n",
    "적절한 모델을 학습시키기 위해서는 주어진 데이터를 training / validation / test 로 나누는 과정이 필수적\n",
    "\n",
    "- 아래는 6:2:2로 나눴지만\n",
    "이외에도 7:1.5:1.5로 나누기도 한다.\n",
    "\n",
    "**validation set**\n",
    "train으로 학습한 데이터 중에 최적의 방법을 찾는 것.<br>\n",
    "그러니 validation set은 학습된 데이터 중 찾는 것이기 때문에 test로 해보는것도 중요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae370e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn이 제공하는 train_test_split 사용\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f647a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 10) (89, 10) (89, 10)\n"
     ]
    }
   ],
   "source": [
    "#데이터 나누기 (6:2:2 비율로)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,y_train, test_size =0.25, random_state =1)\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1632fe1a",
   "metadata": {},
   "source": [
    "### 모델 학습하기\n",
    "Training data를 이용해 회귀분석 모델을 학습하기. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed4df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 import\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8ad2af",
   "metadata": {},
   "source": [
    "Scikit-learn에서 제공하는 LinearRegression 모델을 선언할 때\n",
    "<br>필요한 주요 parameter는 다음과 같다.\n",
    "\n",
    "- **fit_intercept**: 상수항을 사용할 것인지에 대한 여부. True 일 때 상수항 사용. **default=True**\n",
    "- **normalize**: 정규화를 수행할 것인지에 대한 여부. True 일 때 정규화 수행. **default=False**\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "회귀 분석 모델을 학습하기 위해선\n",
    "1. 모델 객체 생성\n",
    "2. 데이터를 이용한 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6994fe01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 객체 생성\n",
    "mlr = LinearRegression() #fit_tintercept, normalize 기본값 사용\n",
    "\n",
    "# 회귀분석 모델 학습\n",
    "mlr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210b7f5",
   "metadata": {},
   "source": [
    "#### 추정한 모델의 회귀 계수 중 가장 영향력 있는 변수는?\n",
    "\n",
    "- coefficient: indepenent variables의 계수\n",
    "- intercept: 상수 (bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e744db5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.87388534119617\n",
      "[ -39.57865915 -236.60328634  489.97259328  352.8678163  -873.03276134\n",
      "  430.03354622  208.4341436   306.03221956  746.84762599  116.37588728]\n"
     ]
    }
   ],
   "source": [
    "# 회귀 계수 확인\n",
    "print(mlr.intercept_)\n",
    "print(mlr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874ec2c6",
   "metadata": {},
   "source": [
    "#### 추정한 모델의 설명력 확인\n",
    "**- 결정계수 R-square**(설명력):<br>\n",
    "독립변수가 종속변수를 얼마만큼 설명해 주는지를 가리키는 지표.<br>\n",
    "\n",
    "R-square을 계산하려면 우선 training data에 대한 예측값을 알아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd87cfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training data 예측값\n",
    "pred_train = mlr.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b09919",
   "metadata": {},
   "source": [
    "scikit-learn에서 제공하는 r2_score 함수를 이용해 R-square 값을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12848f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5353262888595558\n"
     ]
    }
   ],
   "source": [
    "#training data에 대한 R-square 값 계산\n",
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_train,pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fafee6",
   "metadata": {},
   "source": [
    "Validation data, test data의 R-square값도 같은 방법으로 계산해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c76cf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493408590131314\n"
     ]
    }
   ],
   "source": [
    "# validation data에 대한 R-square\n",
    "pred_val = mlr.predict(x_val)\n",
    "print(r2_score(y_val,pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3300394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4432722010710275\n"
     ]
    }
   ],
   "source": [
    "# test data에 대한 R-square\n",
    "pred_test = mlr.predict(x_test)\n",
    "print(r2_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919b75b",
   "metadata": {},
   "source": [
    "## 모델 선택하기\n",
    "\n",
    "### 1. 전진 선택법\n",
    "상수항만 있는 모형에서 시작해, 설명력을 가장 크게 높일 수 있는 변수부터 하나씩 추가해 나가는 방법.<br>\n",
    "- 더 이상 설명력의 이득이 없을 때까지 변수를 추가.\n",
    "\n",
    "*원래는 F 검정을 기준으로 사용해야 하지만, 간단한 구현을 위해 R-square 로 대체한다.*\n",
    "\n",
    "공집합에서 시작해, 매 반복마다 남아 있는 변수들 중 \"추가했을 때 R-square 가 가장 큰 변수\"를 기존의 변수집합에 더해 나가는 방식으로 구현."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6acce10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ round 1 ============\n",
      "best variables updated:  [2]\n",
      "current best r2:  0.4015039066196986\n",
      "============ round 2 ============\n",
      "best variables updated:  [2, 8]\n",
      "current best r2:  0.48019951742375144\n",
      "============ round 3 ============\n",
      "best variables updated:  [2, 8, 6]\n",
      "current best r2:  0.4911801371957262\n",
      "============ round 4 ============\n",
      "best variables updated:  [2, 8, 6, 1]\n",
      "current best r2:  0.514245907690211\n",
      "============ round 5 ============\n",
      "best variables updated:  [2, 8, 6, 1, 3]\n",
      "current best r2:  0.5333863843789604\n",
      "============ round 6 ============\n",
      "no improvement\n",
      "\n",
      "---------------------------------------------------\n",
      "\n",
      "final variables:  [1, 2, 3, 6, 8]\n",
      "final r2:  0.5333863843789604\n"
     ]
    }
   ],
   "source": [
    "# 선택된 변수들, R-square 값 및 모델 저장\n",
    "best_variables = []\n",
    "best_r2 = 0.\n",
    "best_model = None\n",
    "\n",
    "# 남아 있는 변수들\n",
    "remain_variables = list(range(10))\n",
    "\n",
    "for round in range(10):\n",
    "    print(f\"============ round {round+1} ============\")\n",
    "    r2_of_this_round = []\n",
    "    models_of_this_round = []\n",
    "\n",
    "    for var in remain_variables:\n",
    "        # 사용될 변수들과 모델\n",
    "        use_vars = best_variables + [var]\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # 지정된 변수만 사용하게끔 데이터 추출\n",
    "        x_train_small = x_train[:, use_vars]\n",
    "        x_val_small = x_val[:, use_vars]\n",
    "\n",
    "        # 지정된 변수로 모델 학습\n",
    "        model.fit(x_train_small, y_train)\n",
    "        models_of_this_round.append(model)\n",
    "\n",
    "        # validation R-square(설명력) 계산\n",
    "        r2 = r2_score(y_val, model.predict(x_val_small))\n",
    "        r2_of_this_round.append(r2)\n",
    "  \n",
    "    # R-square 가 높은 모델 선택\n",
    "    best_r2_of_this_round = np.max(r2_of_this_round)\n",
    "\n",
    "    # 이전 round와 비교\n",
    "    if best_r2_of_this_round > best_r2:\n",
    "        best_var_of_this_round = np.argmax(r2_of_this_round)\n",
    "\n",
    "        # 변수 추가, R-square 값 및 모델 업데이트\n",
    "        best_variables.append(remain_variables[best_var_of_this_round])\n",
    "        best_r2 = best_r2_of_this_round\n",
    "        best_model = models_of_this_round[best_var_of_this_round]\n",
    "\n",
    "        # 남은 변수들 중 선택된 변수 제거\n",
    "        remain_variables.pop(best_var_of_this_round)\n",
    "\n",
    "        print('best variables updated: ', best_variables)\n",
    "        print('current best r2: ', best_r2)\n",
    "\n",
    "  # 더 이상 개선되지 않으면 멈춤  \n",
    "    else:\n",
    "        print(\"no improvement\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "print('\\n---------------------------------------------------\\n')\n",
    "print('final variables: ', sorted(best_variables))\n",
    "print('final r2: ', best_r2)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf32fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test r2: 0.42090782097560653\n"
     ]
    }
   ],
   "source": [
    "#test set 확인\n",
    "print(\"test r2:\",r2_score(y_test, best_model.predict(x_test[:, best_variables])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90cc00d",
   "metadata": {},
   "source": [
    "결정계수 R-square 를 알고 있을 때, 수정 결정계수 adjusted R-square 를 다음과 같이 계산.\n",
    "\n",
    "####  adjusted R-square을 하는 이유\n",
    "먼저,\n",
    "- R-square(=결정계수=설명력)\n",
    "회귀 모델에서 독립변수(x)가 종속변수(y)를 얼만큼 설명해 주는지 가리키는 지표.<br>\n",
    "\n",
    "**높을수록** 독립변수가 종속변수를 많이 설명한다는 것.\n",
    "<br>\n",
    "-> 실제, 종속변수를 잘 설명하지 못하는 변수가 추가되어도 증가하기 때문에 결정계수만 가지고 판단하는 것은 문제가 있다.\n",
    "\n",
    "#### 따라서 Adjusted R-Squared를 사용한다.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b50f3c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3718968422339797\n"
     ]
    }
   ],
   "source": [
    "# test data에 대한 adjust R-square 계산\n",
    "pred_test = mlr.predict(x_test)\n",
    "test_r2 = r2_score(y_test, pred_test)\n",
    "test_adj_r2 = 1-(1-test_r2)*(y_test.shape[0]-1)/(y_test.shape[0]-x_test.shape[1]-1)\n",
    "print(test_adj_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16f1664",
   "metadata": {},
   "source": [
    "Adjusted R-square을 이용한 \n",
    "## 2. 후진 제거법 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6f3c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ round 1 ============\n",
      "best variables updated:  [0, 1, 2, 3, 4, 5, 6, 8, 9]\n",
      "current best r2:  0.44968750331058116\n",
      "============ round 2 ============\n",
      "best variables updated:  [0, 1, 2, 3, 4, 5, 6, 8]\n",
      "current best r2:  0.468224109131373\n",
      "============ round 3 ============\n",
      "best variables updated:  [0, 1, 2, 3, 5, 6, 8]\n",
      "current best r2:  0.47847527149248936\n",
      "============ round 4 ============\n",
      "best variables updated:  [0, 1, 2, 3, 6, 8]\n",
      "current best r2:  0.49917040260293344\n",
      "============ round 5 ============\n",
      "best variables updated:  [1, 2, 3, 6, 8]\n",
      "current best r2:  0.5052771304258852\n",
      "============ round 6 ============\n",
      "no improvement\n",
      "---------------------------------------------------\n",
      "final variables:  [1, 2, 3, 6, 8]\n",
      "final adj_r2:  0.5052771304258852\n",
      "---------------------------------------------------\n",
      "test adjust R-square:  0.3860227499500407\n"
     ]
    }
   ],
   "source": [
    "# 선택된 변수들, R-square 값 및 모델 저장\n",
    "best_variables = list(range(10))\n",
    "best_adj_r2 = 0.\n",
    "best_model = None\n",
    "\n",
    "\n",
    "# 선택된 변수들 중 Adjusted R-square의 손실이 가장 적은 변수를 골라 없애기\n",
    "for round in range(10):\n",
    "    print(f\"============ round {round+1} ============\")\n",
    "    adj_r2_of_this_round = []\n",
    "    models_of_this_round = []\n",
    "\n",
    "    for var in best_variables:\n",
    "        # 사용될 변수들과 모델\n",
    "        use_vars = best_variables.copy()\n",
    "        use_vars.remove(var)\n",
    "        model = LinearRegression()\n",
    "\n",
    "        # 지정된 변수만 사용하게끔 데이터 추출\n",
    "        x_train_small = x_train[:, use_vars]\n",
    "        x_val_small = x_val[:, use_vars]\n",
    "\n",
    "        # 지정된 변수로 모델 학습\n",
    "        model.fit(x_train_small, y_train)\n",
    "        models_of_this_round.append(model)\n",
    "\n",
    "        # validation adjusted R-square 계산\n",
    "        r2 = r2_score(y_val, model.predict(x_val_small))\n",
    "        adj_r2 = 1 - (1-r2)*(y_val.shape[0]-1)/(y_val.shape[0]-len(use_vars)-1)\n",
    "        adj_r2_of_this_round.append(adj_r2)\n",
    "\n",
    "  # R-square 가 높은 모델 선택\n",
    "    best_adj_r2_of_this_round = np.max(adj_r2_of_this_round)\n",
    "\n",
    "  # 이전 round와 비교\n",
    "    if best_adj_r2_of_this_round > best_adj_r2:\n",
    "        max_var = np.argmax(adj_r2_of_this_round)\n",
    "        best_variables.pop(max_var)\n",
    "        best_adj_r2 = best_adj_r2_of_this_round\n",
    "        best_model = models_of_this_round[max_var]\n",
    "\n",
    "        print('best variables updated: ', best_variables)\n",
    "        print('current best r2: ', best_adj_r2)\n",
    "\n",
    "  # 더 이상 개선되지 않으면 멈춤\n",
    "    else:\n",
    "        print(\"no improvement\")\n",
    "        break\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "print('final variables: ', sorted(best_variables))\n",
    "print('final adj_r2: ', best_adj_r2)\n",
    "\n",
    "print('---------------------------------------------------')\n",
    "test_r2=r2_score(y_test, best_model.predict(x_test[:, best_variables]))\n",
    "test_adj_r2 =1-(1-test_r2)*(y_test.shape[0]-1)/(y_test.shape[0]-len(best_variables)-1) \n",
    "print('test adjust R-square: ', test_adj_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef4e4d3",
   "metadata": {},
   "source": [
    "## 회귀모형의 검정\n",
    "Statsmodels 패키지에서는 OLS 라는 클래스를 이용하여 회귀분석을 진행한다. 아래와 같은 방식으로 학습을 진행하고 각종 테스트 결과를 확인.\n",
    "<br>\n",
    "\n",
    "*Scikit-learn에서와 다른 점 중 하나는 객체를 생성할 때 데이터를 미리 입력해주어야 한다는 것이고, 또 하나는 상수항을 따로 추가해 주어야 한다*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64fc4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "import statsmodels.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08d9d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.535\n",
      "Model:                            OLS   Adj. R-squared:                  0.517\n",
      "Method:                 Least Squares   F-statistic:                     29.15\n",
      "Date:                Thu, 08 Jul 2021   Prob (F-statistic):           7.63e-37\n",
      "Time:                        15:41:33   Log-Likelihood:                -1417.7\n",
      "No. Observations:                 264   AIC:                             2857.\n",
      "Df Residuals:                     253   BIC:                             2897.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        147.8739      3.284     45.033      0.000     141.407     154.341\n",
      "x1           -39.5787     78.455     -0.504      0.614    -194.086     114.929\n",
      "x2          -236.6033     77.891     -3.038      0.003    -390.001     -83.206\n",
      "x3           489.9726     83.570      5.863      0.000     325.391     654.554\n",
      "x4           352.8678     83.710      4.215      0.000     188.010     517.725\n",
      "x5          -873.0328    502.031     -1.739      0.083   -1861.724     115.659\n",
      "x6           430.0335    399.058      1.078      0.282    -355.865    1215.932\n",
      "x7           208.4341    262.438      0.794      0.428    -308.407     725.276\n",
      "x8           306.0322    202.097      1.514      0.131     -91.974     704.038\n",
      "x9           746.8476    214.720      3.478      0.001     323.982    1169.713\n",
      "x10          116.3759     83.117      1.400      0.163     -47.314     280.066\n",
      "==============================================================================\n",
      "Omnibus:                        3.288   Durbin-Watson:                   2.072\n",
      "Prob(Omnibus):                  0.193   Jarque-Bera (JB):                2.430\n",
      "Skew:                          -0.070   Prob(JB):                        0.297\n",
      "Kurtosis:                       2.551   Cond. No.                         215.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "sm_model = OLS(y_train, statsmodels.api.add_constant(x_train))\n",
    "\n",
    "sm_model = sm_model.fit()\n",
    "print(sm_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9507d8",
   "metadata": {},
   "source": [
    "#### 다중공선성을 확인할 수 있는 VIF를 계산해 보자.\n",
    "\n",
    "- 다중공선성이 높다: 예측 값의 신뢰구간이 넓게 형성되는 현상\n",
    "- 다중공선성이 있다:\n",
    "변수들 간 상관관계가 높다.\n",
    "(회귀분석의 기존 전제가 무너진 것이기 때문에 다중공선성을 없애기 위해 노력해야 한다.)<br>\n",
    "\n",
    "그러나 다중공선성은 상관관계가 높지만 상관관계가 높다고 다중공선성이 반드시 있는 것은 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e7b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "218aa7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF of x1: 1.26\n",
      "VIF of x2: 1.28\n",
      "VIF of x3: 1.48\n",
      "VIF of x4: 1.47\n",
      "VIF of x5: 52.46\n",
      "VIF of x6: 33.02\n",
      "VIF of x7: 14.75\n",
      "VIF of x8: 9.38\n",
      "VIF of x9: 9.72\n",
      "VIF of x10: 1.50\n"
     ]
    }
   ],
   "source": [
    "for i in range(x_train.shape[1]):\n",
    "  print(f\"VIF of x{i+1}: {variance_inflation_factor(x_train, i):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19c557",
   "metadata": {},
   "source": [
    "다중공선성이 확인된 변수를 제외한 모델을 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc4fe4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.504\n",
      "Model:                            OLS   Adj. R-squared:                  0.490\n",
      "Method:                 Least Squares   F-statistic:                     37.13\n",
      "Date:                Thu, 08 Jul 2021   Prob (F-statistic):           1.18e-35\n",
      "Time:                        15:46:41   Log-Likelihood:                -1426.4\n",
      "No. Observations:                 264   AIC:                             2869.\n",
      "Df Residuals:                     256   BIC:                             2897.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        148.3556      3.371     44.008      0.000     141.717     154.994\n",
      "x1           -85.9023     79.640     -1.079      0.282    -242.735      70.930\n",
      "x2          -152.5415     77.133     -1.978      0.049    -304.438      -0.645\n",
      "x3           543.3405     83.537      6.504      0.000     378.833     707.848\n",
      "x4           311.1688     85.288      3.648      0.000     143.213     479.125\n",
      "x5           119.2819     94.077      1.268      0.206     -65.982     304.546\n",
      "x6           459.4696    101.144      4.543      0.000     260.290     658.649\n",
      "x7           130.0925     85.305      1.525      0.128     -37.896     298.081\n",
      "==============================================================================\n",
      "Omnibus:                        9.748   Durbin-Watson:                   2.036\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):                4.766\n",
      "Skew:                          -0.010   Prob(JB):                       0.0923\n",
      "Kurtosis:                       2.342   Cond. No.                         36.8\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# 다중공선성이 확인된 변수들을 제외하고 회귀분석 학습하고 결과 출력하기(statsmodels 이용)\n",
    "use_variables = [i for i in range(x_train.shape[1]) if variance_inflation_factor(x_train, i) < 10]\n",
    "small_model = OLS(y_train, statsmodels.api.add_constant(x_train[:, use_variables]))\n",
    "\n",
    "small_model = small_model.fit()\n",
    "print(small_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f2ccb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20719b6ddf0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(pred_train, y_train - pred_train)\n",
    "plt.plot([pred_train.min(), pred_train.max()], [0, 0], '--', color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b6b69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
